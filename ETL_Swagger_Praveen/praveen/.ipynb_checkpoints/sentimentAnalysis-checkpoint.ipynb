{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the keyword to be analyzed : #postnord\n",
      "Enter the number of tweets to be analyzed : 1000\n",
      " \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'TextBlob' has no attribute 'exceptions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotTranslated\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-51d905fbaae3>\u001b[0m in \u001b[0;36mget_tweet_sentiment\u001b[0;34m(self, tweet)\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0;32mtry\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                         \u001b[0manalysis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_tweet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en-US'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotTranslated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/textblob/blob.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(self, from_lang, to)\u001b[0m\n\u001b[1;32m    546\u001b[0m         return self.__class__(self.translator.translate(self.raw,\n\u001b[0;32m--> 547\u001b[0;31m                               from_lang=from_lang, to_lang=to))\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/textblob/translate.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(self, source, from_lang, to_lang, host, type_)\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/textblob/translate.py\u001b[0m in \u001b[0;36m_validate_translation\u001b[0;34m(self, source, result)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotTranslated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Translation API returned the input string unchanged.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotTranslated\u001b[0m: Translation API returned the input string unchanged.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-51d905fbaae3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;31m# calling main function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-51d905fbaae3>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;31m# calling function to get tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;31m#tweets = api.get_tweets(query = 'realDonaldTrump', count = 200)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-51d905fbaae3>\u001b[0m in \u001b[0;36mget_tweets\u001b[0;34m(self, query, count)\u001b[0m\n\u001b[1;32m     91\u001b[0m                                 \u001b[0mparsed_tweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                                 \u001b[0;31m# saving sentiment of tweet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                                 \u001b[0mparsed_tweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tweet_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                                 \u001b[0mparsed_tweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'enriched'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_tweet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-51d905fbaae3>\u001b[0m in \u001b[0;36mget_tweet_sentiment\u001b[0;34m(self, tweet)\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0;32mtry\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                         \u001b[0manalysis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_tweet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en-US'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotTranslated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;31m# set sentiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'TextBlob' has no attribute 'exceptions'"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import tweepy \n",
    "from tweepy import OAuthHandler \n",
    "from textblob import TextBlob \n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem.porter import *\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import time\n",
    "from operator import itemgetter \n",
    "from itertools import chain \n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "#from nltk.corpus import stopwords\n",
    "\n",
    "class TwitterClient(object): \n",
    "\t''' \n",
    "\tGeneric Twitter Class for sentiment analysis. \n",
    "\t'''\n",
    "\n",
    "\tdef __init__(self): \n",
    "\t\t''' \n",
    "\t\tClass constructor or initialization method. \n",
    "\t\t'''\n",
    "\t\t# keys and tokens from the Twitter Dev Console \n",
    "\t\tconsumer_key = 'JTrrb24OiDSCaBfqrPuvv9Xl2'\n",
    "\t\tconsumer_secret = 'gcbR7NkdpJSfOWvDzLpgA73KT9CxY46NGJzErCIPE5noCdTEoG'\n",
    "\t\taccess_token = '1121603288560836609-AvlTRUvmeznTcVBWelIXonH1Gbc8Bq'\n",
    "\t\taccess_token_secret = 'CKkFhuskaNixMc23JmX3lyLsTO9nGoPKkWkyRUiDjU25M'\n",
    "\n",
    "\t\t# attempt authentication \n",
    "\t\ttry: \n",
    "\t\t\t# create OAuthHandler object \n",
    "\t\t\tself.auth = OAuthHandler(consumer_key, consumer_secret) \n",
    "\t\t\t# set access token and secret \n",
    "\t\t\tself.auth.set_access_token(access_token, access_token_secret) \n",
    "\t\t\t# create tweepy API object to fetch tweets \n",
    "\t\t\t#self.api = tweepy.API(self.auth, proxy = \"https://172.28.137.11:3128\") \n",
    "\t\t\t#self.api = tweepy.API(self.auth, proxy = \"https:////172.30.19.16:3128\") \n",
    "\t\t\tself.api = tweepy.API(self.auth) \n",
    "            #self.api.wait_on_rate_limit = True;\n",
    "\t\t\t#self.api.wait_on_rate_limit_notify = True;\n",
    "\t\texcept: \n",
    "\t\t\tprint(\"Error: Authentication Failed\") \n",
    "\n",
    "\tdef clean_tweet(self, tweet): \n",
    "\t\t''' \n",
    "\t\tUtility function to clean tweet text by removing links, special characters \n",
    "\t\tusing simple regex statements. \n",
    "\t\t'''\n",
    "\t\treturn  ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t]) |(\\w+:\\/\\/\\S+)\", \" \", tweet).split()) \n",
    "\n",
    "\tdef get_tweet_sentiment(self, tweet): \n",
    "\t\t''' \n",
    "\t\tUtility function to classify sentiment of passed tweet \n",
    "\t\tusing textblob's sentiment method \n",
    "\t\t'''\n",
    "\t\t# create TextBlob object of passed tweet text \n",
    "\t\ttry :\n",
    "\t\t\tanalysis = TextBlob(self.clean_tweet(tweet)).translate(to='en-US') \n",
    "\t\texcept textblob.exceptions.NotTranslated:\n",
    "\t\t\tpass\n",
    "\t\t# set sentiment \n",
    "\t\tif analysis.sentiment.polarity > 0: \n",
    "\t\t\treturn 'positive'\n",
    "\t\telif analysis.sentiment.polarity == 0: \n",
    "\t\t\treturn 'neutral'\n",
    "\t\telse: \n",
    "\t\t\treturn 'negative'\n",
    "\n",
    "\tdef get_tweets(self, query, count = 10): \n",
    "\t\t''' \n",
    "\t\tMain function to fetch tweets and parse them. \n",
    "\t\t'''\n",
    "\t\t# empty list to store parsed tweets \n",
    "\t\ttweets = [] \n",
    "\n",
    "\n",
    "\t\ttry: \n",
    "\t\t\t# call twitter api to fetch tweets \n",
    "\t\t\t#fetched_tweets = self.api.search(q = query, count = count) \n",
    "\n",
    "\n",
    "\t\t\t# parsing tweets one by one \n",
    "\t\t\t#for tweet in tweepy.Cursor(self.api.search, q=query, tweet_mode='extended').items(count): \n",
    "\t\t\tfor tweet in tweepy.Cursor(self.api.search, q=query).items(count): \n",
    "\t\t\t#for tweet in fetched_tweets: \n",
    "\t\t\t\t# empty dictionary to store required params of a tweet \n",
    "\t\t\t\tparsed_tweet = {} \n",
    "\n",
    "\t\t\t\t# saving text of tweet \n",
    "\t\t\t\tparsed_tweet['text'] = tweet.text\n",
    "\t\t\t\t# saving sentiment of tweet \n",
    "\t\t\t\tparsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text)\n",
    "                \n",
    "\t\t\t\tparsed_tweet['enriched'] = self.clean_tweet(tweet.text)\n",
    "                \n",
    "\t\t\t\t#print(parsed_tweet['text'])\n",
    "\t\t\t\t#print(\"self.get_tweet_sentiment(tweet.text) : \"+self.get_tweet_sentiment(tweet.text))\n",
    "\t\t\t\t'''\n",
    "\t\t\t\t# appending parsed tweet to tweets list \n",
    "\t\t\t\tif tweet.retweet_count > 0: \n",
    "\t\t\t\t\t# if tweet has retweets, ensure that it is appended only once \n",
    "\t\t\t\t\tif parsed_tweet not in tweets: \n",
    "\t\t\t\t\t\ttweets.append(parsed_tweet)\n",
    "\t\t\t\telse: \n",
    "\t\t\t\t\ttweets.append(parsed_tweet)\n",
    "\t\t\t\t'''\n",
    "\t\t\t\ttweets.append(parsed_tweet)\n",
    "\t\t\t# return parsed tweets \n",
    "\t\t\t#print(tweet)\n",
    "\t\t\t#print(\"Total number of records : \" + str(len(tweets)))\n",
    "\t\t\treturn tweets \n",
    "\n",
    "\t\texcept tweepy.TweepError as e: \n",
    "\t\t\t# print error (if any) \n",
    "\t\t\tprint(\"Error : \" + str(e)) \n",
    "\t\t\t#exit()\n",
    "\n",
    "def main(): \n",
    "    \n",
    "\t# creating object of TwitterClient Class \n",
    "\tapi = TwitterClient()\n",
    "    \n",
    "\tquery_input = input(\"Enter the keyword to be analyzed : \")\n",
    "\tcount_input = int(input(\"Enter the number of tweets to be analyzed : \"))\n",
    "\tprint(\" \")\n",
    "\t# calling function to get tweets \n",
    "\t#tweets = api.get_tweets(query = 'realDonaldTrump', count = 200)\n",
    "\ttweets = api.get_tweets(query = query_input, count = count_input) \n",
    "    \n",
    "\tif len(tweets) == 0:\n",
    "\t\tctweets = 1\n",
    "\telse:\n",
    "\t\tctweets = len(tweets)\n",
    "\t# picking positive tweets from tweets \n",
    "\tptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'positive'] \n",
    "\t# percentage of positive tweets \n",
    "\tprint(\"Positive tweets percentage: {} %\".format(100*len(ptweets)/ctweets)) \n",
    "\t# picking negative tweets from tweets \n",
    "\tntweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative'] \n",
    "\t# percentage of negative tweets \n",
    "\tprint(\"Negative tweets percentage: {} %\".format(100*len(ntweets)/ctweets)) \n",
    "\t# percentage of neutral tweets \n",
    "\tprint(\"Neutral tweets percentage: {} % \".format(100*(len(tweets) - len(ntweets) - len(ptweets))/ctweets))\n",
    "\n",
    "\tht=''\n",
    "\tall_words = ''\n",
    "\thashtags = []    \n",
    "\tfor tweet in tweets[:]:\n",
    "\t\tht = re.findall(r\"#(\\w+)\", tweet['enriched'])\n",
    "\t\thashtags.append(ht)        \n",
    "\t\tall_words = all_words + ' ' + tweet['enriched']\n",
    "    \n",
    "\tall_words = all_words.lower()\n",
    "\tall_ptweets_list = []\n",
    "\tall_ptweets_list = [ tweet['enriched'] for tweet in tweets if tweet['sentiment'] == 'positive']\n",
    "\tall_ptweets_list = (' '.join(all_ptweets_list)).split()\n",
    "\n",
    "\tall_ptweets_mc_list = []\n",
    "\tfor word, count in Counter(all_ptweets_list).most_common(100):\n",
    "\t\tall_ptweets_mc_list.append(word)\n",
    "    \n",
    "\tall_ptweets_mc = ''\n",
    "\n",
    "\thashtags_pos = []\n",
    "\tfor word in all_ptweets_list:\n",
    "\t\tht = re.findall(r\"#(\\w+)\", word)\n",
    "\t\thashtags_pos.append(ht)\n",
    "\t\tif word in all_ptweets_mc_list:\n",
    "\t\t\tall_ptweets_mc = all_ptweets_mc + ' ' + word\n",
    "\n",
    "    #negetive tweets most common words\n",
    "\tall_ntweets_list = []\n",
    "\tall_ntweets_list = [ tweet['enriched'] for tweet in tweets if tweet['sentiment'] == 'negative']\n",
    "\tall_ntweets_list = (' '.join(all_ntweets_list)).split()\n",
    "\n",
    "\tall_ntweets_mc_list = []\n",
    "\tfor word, count in Counter(all_ntweets_list).most_common(100):\n",
    "\t\tall_ntweets_mc_list.append(word)\n",
    "    \n",
    "\tall_ntweets_mc = ''\n",
    "\thashtags_neg = []\n",
    "\tfor word in all_ntweets_list:\n",
    "\t\tht = re.findall(r\"#(\\w+)\", word)\n",
    "\t\thashtags_neg.append(ht)\n",
    "\t\tif word in all_ntweets_mc_list:\n",
    "\t\t\tall_ntweets_mc = all_ntweets_mc + ' ' + word\n",
    "\t#print(all_ntweets_mc)\n",
    "\n",
    "\t#print(\"all_words : \" + all_words)\n",
    "\ttweet_perc = []\n",
    "\ttweet_perc.append(len(ptweets))\n",
    "\ttweet_perc.append(len(ntweets))\n",
    "\ttweet_perc.append(len(tweets) - len(ntweets) - len(ptweets))\n",
    "\tlables = ['Positive', 'Negetive', 'Nuetral']\n",
    "\tcolors = ['g', 'r', 'b']\n",
    "\tplt.title('PieChart for Tweet Analysis')\n",
    "\tplt.pie(tweet_perc, labels=lables, colors=colors, shadow=True, startangle=90, autopct='%.1f%%')\n",
    "\t#plt.show()\n",
    "\t#print(\"ptweets\", len(ptweets))\n",
    "\t#print(\"ntweets\", len(ntweets))\n",
    "\t#print(\"tweets\", len(tweets))\n",
    "\tstopwords = list(STOPWORDS) \n",
    "\t#stop = stopwords.words('english') + ['rt', 'RT', 'the', 'The', 'will', 'https', \"we're\", \"it's\", '&amp', 'make', 'bring', 'much', ]\n",
    "\tstop = stopwords + ['rt', 'RT', 'the', 'The', 'will', 'https', '']\n",
    "\n",
    "\t#WordCloud for all words\n",
    "\twordcloud = WordCloud(width = 800, height = 800,stopwords = stop, min_font_size = 10).generate(all_words) \n",
    "\tplt.figure(figsize = (8, 8), facecolor = None) \n",
    "\tplt.imshow(wordcloud, interpolation=\"bilinear\") \n",
    "\tplt.axis(\"off\") \n",
    "\tplt.tight_layout(pad = 0) \n",
    "\tplt.title('WordCloud for ALL Comments')\n",
    "\tplt.show() \n",
    "    \n",
    "\t#print(\"WordCloud for Positive Comments ------------>\")\n",
    "\twordcloud = WordCloud(width = 800, height = 800,stopwords = stop, min_font_size = 10).generate(all_ptweets_mc) \n",
    "  \n",
    "# plot the WordCloud image                        \n",
    "\tplt.figure(figsize = (8, 8), facecolor = None) \n",
    "\tplt.imshow(wordcloud, interpolation=\"bilinear\") \n",
    "\tplt.axis(\"off\") \n",
    "\tplt.tight_layout(pad = 0) \n",
    "\tplt.title('WordCloud for Positive Comments')\n",
    "\tplt.show() \n",
    "\n",
    "\n",
    "\t#print(\"WordCloud for Negetive Comments ------------>\")\n",
    "\tif(len(all_ntweets_mc) > 0) :\n",
    "\t\twordcloud = WordCloud(width = 800, height = 800,stopwords = stop, min_font_size = 10).generate(all_ntweets_mc) \n",
    "\t\tplt.figure(figsize = (8, 8), facecolor = None) \n",
    "\t\tplt.imshow(wordcloud, interpolation=\"bilinear\") \n",
    "\t\tplt.axis(\"off\") \n",
    "\t\tplt.tight_layout(pad = 0) \n",
    "\t\tplt.title('WordCloud for Negetive Comments')\n",
    "\t\tplt.show()\n",
    "    \n",
    "    #Horizontal bar chart for most common words\n",
    "\tall_words_without_stop_wd = ''\n",
    "\tfor word in all_words.split():\n",
    "\t\tif word.lower() not in stop and len(word) > 3:\n",
    "\t\t\tall_words_without_stop_wd = all_words_without_stop_wd + ' ' + word#stemmer.stem(word)\n",
    "\tall_words_without_stop_wd = re.sub(r\"#(\\w+)\",'', all_words_without_stop_wd) # remove hashtags\n",
    "\tdf = pd.DataFrame(sorted(Counter(all_words_without_stop_wd.split()).most_common(15),key = itemgetter(1)), columns = ['word', 'count'])\n",
    "\tdf.plot.barh(x='word', title='Most Common Words')\n",
    "\n",
    "\tall_pos_words_without_stop_wd = ''\n",
    "\tfor word in all_ptweets_list:\n",
    "\t\tif word.lower() not in stop and len(word) > 3:\n",
    "\t\t\tall_pos_words_without_stop_wd = all_pos_words_without_stop_wd + ' ' + word.lower()#stemmer.stem(word)\n",
    "\tall_pos_words_without_stop_wd = re.sub(r\"#(\\w+)\",'', all_pos_words_without_stop_wd) # remove hashtags\n",
    "\tdf = pd.DataFrame(sorted(Counter(all_pos_words_without_stop_wd.split()).most_common(15),key = itemgetter(1)), columns = ['word', 'count'])\n",
    "\tdf.plot.barh(x='word', title='Most Postive Words', color=['green'])\n",
    "\n",
    "\tall_neg_words_without_stop_wd = ''\n",
    "\tfor word in all_ntweets_list:\n",
    "\t\tif word.lower() not in stop and len(word) > 3:\n",
    "\t\t\tall_neg_words_without_stop_wd = all_neg_words_without_stop_wd + ' ' + word.lower()#stemmer.stem(word)\n",
    "\tall_neg_words_without_stop_wd = re.sub(r\"#(\\w+)\",'', all_neg_words_without_stop_wd) # remove hashtags\n",
    "\tif(len(all_neg_words_without_stop_wd) > 0) :\n",
    "\t\tdf = pd.DataFrame(sorted(Counter(all_neg_words_without_stop_wd.split()).most_common(15),key = itemgetter(1)), columns = ['word', 'count'])\n",
    "\t\tdf.plot.barh(x='word', title='Most Negetive Words', color=['red'])\n",
    "    \n",
    "\tprint(\"\")\n",
    "    #Trend analysis\n",
    "\tif len(Counter(sum(hashtags, [])).most_common(15)) > 0 :\n",
    "\t\t#print(\"Hashtag trends with Positive Tweets ------------>\")\n",
    "\t\tdf = pd.DataFrame(Counter(sum(hashtags, [])).most_common(15), columns = ['Hashtags', 'Count'])\n",
    "\t\tdf.plot.bar(x='Hashtags', y='Count', title='Trends Analysis')   \n",
    "\telse:\n",
    "\t\tprint(\"No Hashtags associated with Tweets\")\n",
    "        \n",
    "\t#print(Counter(sum(hashtags_pos, [])).most_common(10))\n",
    "\tif len(Counter(sum(hashtags_pos, [])).most_common(15)) > 0 :\n",
    "\t\t#print(\"Hashtag trends with Positive Tweets ------------>\")\n",
    "\t\tdf = pd.DataFrame(Counter(sum(hashtags_pos, [])).most_common(15), columns = ['Hashtags', 'Count'])\n",
    "\t\tdf.plot.bar(x='Hashtags', y='Count', title='Trends with Positive Tweets')   \n",
    "\telse:\n",
    "\t\tprint(\"No Hashtags associated with Positive Tweets\")    \n",
    "\n",
    "\t#print(Counter(sum(hashtags_neg, [])).most_common(10))\n",
    "\tif(len(Counter(sum(hashtags_neg, [])))) > 0:\n",
    "\t\t#print(\"Hashtag trends with Negetive Tweets ------------>\")\n",
    "\t\tdf = pd.DataFrame(Counter(sum(hashtags_neg, [])).most_common(15), columns = ['Hashtags', 'Count'])\n",
    "\t\tdf.plot.bar(x='Hashtags', y='Count', title='Trends with Negetive Tweets')   \n",
    "\telse:\n",
    "\t\tprint(\"No Hashtags associated with Negetive Tweets\")\n",
    "        \n",
    "\t# printing first 5 positive tweets \n",
    "\tprint(\"\\n\\nPositive tweets:\") \n",
    "\tfor tweet in ptweets[:10]: \n",
    "\t\tprint(tweet['text']) \n",
    "\n",
    "\t# printing first 5 negative tweets \n",
    "\tprint(\"\\n\\nNegative tweets:\")   \n",
    "\tfor tweet in ntweets[:10]: \n",
    "\t\tprint(tweet['text']) \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\t# calling main function \n",
    "\tmain() \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
